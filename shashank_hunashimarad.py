# -*- coding: utf-8 -*-
"""shashank_hunashimarad

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HFpHli6YyOWVm5gn2-YN4H-ke6CTfjI-
"""

import pandas as pd
import sklearn
import numpy as np
from sklearn.preprocessing import LabelEncoder # used for encoding categorical data
from sklearn.model_selection import train_test_split # used for splitting training and testing data
from sklearn.preprocessing import StandardScaler # used for feature scaling
import sklearn.model_selection as model_selection
#importing various classifiers
from sklearn import svm
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix

pd.read_csv("/content/drive/My Drive/DS_DATESET.csv") #for reading dataset



#removing all unwanted columns from the dataset
dataset = pd.read_csv('/content/drive/My Drive/DS_DATESET.csv') # to import the dataset into a variable

#dataset.drop([],axis=1)
#dataset.drop([],axis=1)
dataset.drop(['First Name','Last Name','City','Certifications/Achievement/ Research papers','Link to updated Resume (Google/ One Drive link preferred)', 'link to Linkedin profile','State','DOB [DD/MM/YYYY]', 'Email Address','Contact Number', 'Emergency Contact Number','Zip Code','How Did You Hear About This Internship?','Current Employment Status','Course Type','Degree','Course Type'], axis=1, inplace=True)

#pre-processing the data
continuous_data=dataset.select_dtypes(include=[np.number])
categorical_data=dataset.select_dtypes(exclude=[np.number])

continuous_data.head()

categorical_data.head()

print(dataset.isnull().sum())

#encoding the categorical data
lEnc=LabelEncoder()
for i in categorical_data:
  categorical_data[i]=lEnc.fit_transform(categorical_data[i])
categorical_data.head()



#splitting the data into testing and training

x=categorical_data.iloc[:,:-1]
y=categorical_data.iloc[:,-1]

X_train, X_test, y_train, y_test = model_selection.train_test_split(x, y, train_size=0.8,test_size=0.2, random_state=0)

#using decision tree classifier
classifier_entropy = DecisionTreeClassifier(criterion='entropy')
classifier_entropy.fit(X_train, y_train)
 
dtc=classifier_entropy.score(X_test, y_test)

print(dtc*100)

#using svm classifier
cla_svm = svm.SVC(kernel='rbf') 
cla_svm.fit(X_train, y_train)

sv=cla_svm.score(X_test,y_test)
print(sv*100)

#using random forest classifier
cla_for=RandomForestClassifier(criterion='entropy')
cla_for.fit(X_train,y_train)
forest=cla_for.predict(X_test)
cla_for.score(X_test,y_test)
print(f1_score(y_test,forest))

#score is 92.34%

